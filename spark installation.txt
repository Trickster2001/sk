1. open ubantu >> terminal >> 
2. su hdoop >> password
3. cd ..
4. cd ..
5. sudo apt install scala >> give password
6. scala -version
7. sudo wget https://dlcdn.apache.org/spark/spark-3.3.3/spark-3.3.3-bin-hadoop3.tgz
8. sudo tar -xvf spark-3.3.3-bin-hadoop3.tgz
9. sudo mkdir /opt/spark
10. sudo mv spark-3.3.3-bin-hadoop3/* /opt/spark 
11. sudo chmod -R 777 /opt/spark
12. sudo nano ~/.bashrc
13. add this two line below code

export SPARK_HOME=/opt/spark
export PATH=$PATH:SPARK_HOME/bin:$SPARK_HOME/sbin

save 

14. start-master.sh
15. open brw and type localhost:8080 
16. copy url 
17. start-worker.sh [peast that url]
18. go to brw abd check status in worker id 
19. jps
20. spark-shell